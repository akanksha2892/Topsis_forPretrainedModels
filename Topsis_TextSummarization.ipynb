{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8LxoAf-yE-x",
        "outputId": "e5af7f03-f1ba-48df-edd8-8bd579cc69fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Ranking:\n",
            "             Model  TOPSIS_Score  Rank\n",
            "5   BERTExtractive      0.764847   1.0\n",
            "10            BART      0.763225   2.0\n",
            "2       DistilBERT      0.741507   3.0\n",
            "6       BERTSumExt      0.722648   4.0\n",
            "0       BERTSumAbs      0.656395   5.0\n",
            "7               T5      0.618393   6.0\n",
            "4             CTRL      0.607168   7.0\n",
            "9            XLNet      0.501730   8.0\n",
            "1            GPT-2      0.498270   9.0\n",
            "8          Pegasus      0.291946  10.0\n",
            "3        BARTLarge      0.235153  11.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data from the CSV file\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "# Extract relevant columns\n",
        "rouge_scores = data['Rouge_Scores'].values\n",
        "length_of_summary = data['Length_of_Summary'].values\n",
        "training_time = data['Training_Time'].values\n",
        "\n",
        "# Weights for each parameter\n",
        "weights = np.array([0.4, 0.3, 0.3])\n",
        "\n",
        "# Normalize the matrix\n",
        "normalized_matrix = np.column_stack([\n",
        "    rouge_scores / np.max(rouge_scores),\n",
        "    1 - (length_of_summary / np.max(length_of_summary)),\n",
        "    1 - (training_time / np.max(training_time))\n",
        "])\n",
        "\n",
        "# Calculate the weighted normalized decision matrix\n",
        "weighted_normalized_matrix = normalized_matrix * weights\n",
        "\n",
        "# Ideal and Negative Ideal solutions\n",
        "ideal_solution = np.max(weighted_normalized_matrix, axis=0)\n",
        "negative_ideal_solution = np.min(weighted_normalized_matrix, axis=0)\n",
        "\n",
        "# Calculate the separation measures\n",
        "distance_to_ideal = np.sqrt(np.sum((weighted_normalized_matrix - ideal_solution)**2, axis=1))\n",
        "distance_to_negative_ideal = np.sqrt(np.sum((weighted_normalized_matrix - negative_ideal_solution)**2, axis=1))\n",
        "\n",
        "# Calculate the TOPSIS scores\n",
        "topsis_scores = distance_to_negative_ideal / (distance_to_ideal + distance_to_negative_ideal)\n",
        "\n",
        "# Rank the models based on TOPSIS scores\n",
        "data['TOPSIS_Score'] = topsis_scores\n",
        "data['Rank'] = data['TOPSIS_Score'].rank(ascending=False)\n",
        "\n",
        "# Print the results\n",
        "print(\"Model Ranking:\")\n",
        "print(data[['Model', 'TOPSIS_Score', 'Rank']].sort_values(by='Rank'))\n",
        "\n",
        "data.to_csv('result.csv', index=False)"
      ]
    }
  ]
}